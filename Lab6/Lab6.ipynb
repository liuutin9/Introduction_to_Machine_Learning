{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V7Zsk2Cyjcr0"
   },
   "source": [
    "## Import Packages\n",
    "\n",
    "1. To build a recurrent neural network, we start by importing the Dense layer, Activation layer, and Loss function that you implemented in Lab4 & Flatten layer you implemented in Lab5. Ensure the following three files are located in the same directory as this notebook, and follow the instructions to complete the setup:\n",
    "    - Dense.py : Copy the **Dense class** you had implemented in Lab4 to it.\n",
    "    - Activation.py : Copy the **Activation class** you had implemented in Lab4 to it.\n",
    "    - Loss.py : Copy **compute_CCE_loss** function you had implemented in Lab4 to it.\n",
    "    - Flatten.py: Copy **Flatten class** you had implemented in Lab5 to it.\\\n",
    "    Note: you should copy both `forward()` and `backward()` in class `Flatten` in Lab5.\n",
    "\n",
    "\n",
    "⚠️ **WARNING** ⚠️:\n",
    "*   Please do not import any other packages in this lab.\n",
    "*   np.random.seed(seed) is used to keep all the random function calls consistent. It will help us grade your work. Please don't change the seed.\n",
    "\n",
    "❗ **Important** ❗: Please do not change the code outside this code bracket.\n",
    "```\n",
    "### START CODE HERE ###\n",
    "...\n",
    "### END CODE HERE ###\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PHkPrxmpjkQB"
   },
   "source": [
    "### Mount Google Drive (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6-arb65yjiEf",
    "outputId": "9cd1c8d5-7cfa-4cc4-b3c7-4510f5a97cf8"
   },
   "outputs": [],
   "source": [
    "### START CODE HERE ###\n",
    "# from google.colab import drive\n",
    "import os\n",
    "# drive.mount('/content/drive')\n",
    "# os.chdir('YOUR PATH')\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "id": "poIfFIK0juEr"
   },
   "outputs": [],
   "source": [
    "###### import your Lab4 & Lab5 code (Don't change this part) ######\n",
    "from Dense import Dense\n",
    "from Activation import Activation\n",
    "from Loss import compute_CCE_loss, compute_MSE_loss\n",
    "from Flatten import Flatten\n",
    "##################################\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "outputs = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KAxzqsKx8bRL"
   },
   "source": [
    "# Basic Part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PhkjTLnlPNjq"
   },
   "source": [
    "## RNN Class (30%)\n",
    "The RNN class implements a simple Recurrent Neural Network (RNN) layer. This class includes methods for initializing parameters, performing the forward pass, computing gradients during the backward pass, and updating the weights.\n",
    "\n",
    "Structure overview:\n",
    "<figure> <img src=\"https://imgur.com/nU7xrBe.png\" width=\"580\" height=\"400\">\n",
    "</figure>\n",
    "RNN connection:\n",
    "<figure>\n",
    "<img src=\"https://imgur.com/4JQX0se.png\" width=\"500\" height=\"250\">\n",
    "</figure>\n",
    "Data insights:\n",
    "<figure> <img src=\"https://imgur.com/c2MI3mj.png\" width=\"400\" height=\"220\">\n",
    "</figure>\n",
    "In each neuron:\n",
    "<figure> <img src=\"https://imgur.com/luXS4zv.png\" width=\"300\" height=\"220\">\n",
    "</figure>\n",
    "\n",
    "1.   **Initializaon**\n",
    "\n",
    "    *   `input_size`: The number of input features for each time step.\n",
    "    *   `rnn_units`: The number of units (neurons) in the RNN layer.\n",
    "    *   `seed`: A random seed for weight initialization to ensure reproducibility.\n",
    "\n",
    "2.   **Initialize parameters** (3%)\n",
    "    * `Wx`: The weight matrix for the input to hidden connections. It has a shape of `(rnn_units, input_size)`\n",
    "    * `Wh`: The weight matrix for the hidden to hidden connections. It has a shape of `(rnn_units, rnn_units)`\n",
    "    * `bh`: The bias vector for the hidden state. It has a shape of `(rnn_units, 1)`, where rnn_units is the number of units in the RNN layer.\n",
    "3.  **Forward** (12%) \\\n",
    "* `X`: Input data of shape `(batch_size, timesteps, input_size)`\n",
    "* The forward pass computes the hidden state `h_t` (shape of `(batch_size, self.rnn_units)`)at each time step `t` using the following formula:\n",
    "$ h_t = \\tanh(W_x \\cdot x_t + W_h \\cdot h_{t-1} + b_h)$\n",
    "    * $W_x$ is the weight matrix for the input to hidden connections.\n",
    "    * $W_h$ is the weight matrix for the hidden to hidden connections.\n",
    "    * $b_h$ is the bias vector.\n",
    "    * $x_t$ is the input at time step t.\n",
    "    * $h_{t-1}$ is the hidden state from the previous time step.\n",
    "    * $\\tanh$ is the hyperbolic tangent activation function.\n",
    "* Output would be shape of `(batch_size, rnn_units)`\n",
    "4. **Backward** (15%) \\\n",
    "Reference (Backpropagation Through Time):\n",
    "https://www.pycodemates.com/2023/08/backpropagation-through-time-explained-with-derivations.html\n",
    "* `dH`: Gradient of the loss with respect to the hidden state, typically of shape `(batch_size, rnn_units, 1)`.\n",
    "* The backward pass computes the gradients of the loss with respect to the weights and biases using the following formulas:\n",
    "    * Gradient of the loss with respect to the hidden state(derivative of `tanh`):\\\n",
    "    $\\delta_t = (1 - h_t^2) \\cdot \\delta_{t+1}$\n",
    "        * $\\delta_t$ is the gradient of the loss with respect to the hidden state at time step t.\n",
    "        * $h_t$ is the hidden state at time step t\n",
    "    * Gradients with respect to the weights and biases (accumulate the gradients over all time steps):\n",
    "        1. $\\frac{\\partial L}{\\partial W_x} = ∑_{t=0}^{timesteps} \\delta_t^T \\cdot x_t$\n",
    "        2. $\\frac{\\partial L}{\\partial W_h} = ∑_ {t=0}^{timesteps} \\delta_t^T \\cdot h_{t-1}$\n",
    "        3. $\\frac{\\partial L}{\\partial b_h} = ∑_{t=0}^{timesteps} \\delta_t^T$\n",
    "        * $\\frac{\\partial L}{\\partial W_x}$ is the gradient of the loss with respect to the input to hidden weights.\n",
    "        * $\\frac{\\partial L}{\\partial W_h}$ is the gradient of the loss with respect to the hidden to hidden weights.\n",
    "        * $\\frac{\\partial L}{\\partial b_h}$ is the gradient of the loss with respect to the hidden bias.\n",
    "        * $x_t$ is the input at time step t.\n",
    "        * $h_{t-1}$ is the hidden state from the previous time step.\n",
    "    * Gradient with respect to the previous hidden state:\n",
    "    $\\frac{\\partial L}{\\partial h_{t-1}} = \\delta_t \\cdot W_h$\n",
    "    * Then divide each gradient by `batch_size`.\n",
    "    * Gradient clipping (optional) is recommended in RNN since RNN rely on backpropagation through time where data might contain large timesteps and it might cause gradient explosion or vanishing. **Note**: You can't do gradient clipping in the function testing (`test_baward()`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "id": "Ry3gZ4hUJwUn"
   },
   "outputs": [],
   "source": [
    "class RNN():\n",
    "    def __init__(self, input_size, rnn_units, seed=1):\n",
    "        \"\"\"\n",
    "        Initialize the SimpleRNN layer.\n",
    "\n",
    "        Parameters:\n",
    "        input_size (int): Number of input features.\n",
    "        rnn_units (int): Number of units in the RNN layer.\n",
    "        seed (int): Random seed for weight initialization.\n",
    "        \"\"\"\n",
    "        self.input_size = input_size\n",
    "        self.rnn_units = rnn_units\n",
    "        self.seed = seed\n",
    "        self.initialize_parameters()\n",
    "\n",
    "    def initialize_parameters(self):\n",
    "        \"\"\"\n",
    "        Initialize the weights and biases for the RNN layer.\n",
    "        \"\"\"\n",
    "        np.random.seed(self.seed)\n",
    "\n",
    "        ### START CODE HERE ###\n",
    "        # Multiply by 0.01 is for testing reason.\n",
    "        self.Wx = np.random.randn(self.rnn_units, self.input_size) * 0.01 # Input to hidden weights , with shape of (rnn_units, input_size).\n",
    "        self.Wh = np.random.randn(self.rnn_units, self.rnn_units) * 0.01  # Hidden to hidden weights, with shape of (rnn_units, rnn_units).\n",
    "        self.bh = np.zeros((self.rnn_units, 1))                           # Hidden bias, with shape of (rnn_units, 1).\n",
    "        ### END CODE HERE ###\n",
    "\n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        Perform the forward pass through the RNN layer.\n",
    "\n",
    "        Parameters:\n",
    "        X (ndarray): Input data of shape (batch_size, timesteps, input_size).\n",
    "\n",
    "        Returns:\n",
    "        ndarray: Output of the RNN layer (hidden state).\n",
    "        \"\"\"\n",
    "        batch_size, timesteps, _ = X.shape\n",
    "        ### START CODE HERE ###\n",
    "        self.h = np.zeros((batch_size, self.rnn_units)) # Initialize hidden state, with shape of (batch_size, self.rnn_units).\n",
    "        self.hs = []                                    # Store hidden states for backward pass, list of self.h.\n",
    "        ### END CODE HERE ###\n",
    "\n",
    "        self.xs = []  # Store inputs for backward pass\n",
    "\n",
    "        for t in range(timesteps):\n",
    "            ### START CODE HERE ###\n",
    "            x_t = X[:, t, :] # Get input at time step t for all data in X.\n",
    "            self.xs.append(x_t)\n",
    "            self.h = np.tanh(x_t @ self.Wx.T + self.h @ self.Wh.T + self.bh.T) # Update hidden state according to the formula of h_t.\n",
    "            self.hs.append(self.h)\n",
    "            ### END CODE HERE ###\n",
    "\n",
    "        return self.h\n",
    "\n",
    "\n",
    "    def backward(self, dH):\n",
    "        \"\"\"\n",
    "        Perform the backward pass through the RNN layer.\n",
    "\n",
    "        Parameters:\n",
    "        dH (ndarray): Gradient of the loss with respect to the hidden state.\n",
    "        clip_value (float): Value to clip the gradients to prevent exploding gradients.\n",
    "\n",
    "        Returns:\n",
    "        ndarray: Gradient of the loss with respect to the input.\n",
    "        \"\"\"\n",
    "        batch_size, _ = dH.shape\n",
    "        ### START CODE HERE ###\n",
    "        self.dL_dWx = np.zeros_like(self.Wx) # Initialized with same shape as Wx.\n",
    "        self.dL_dWh = np.zeros_like(self.Wh) # Initialized with same shape as Wh.\n",
    "        self.dL_dbh = np.zeros_like(self.bh) # Initialized with same shape as bh.\n",
    "        ### END CODE HERE ###\n",
    "        dL_dh = dH\n",
    "\n",
    "        for t in reversed(range(len(self.hs))):\n",
    "            x_t = self.xs[t]  # Get input at time step t\n",
    "            h = self.hs[t]\n",
    "            h_prev = self.hs[t-1] if t > 0 else np.zeros_like(h)\n",
    "            ### START CODE HERE ###\n",
    "            dL_dh_raw = (1 - h**2) * dL_dh                                     # Derivative of tanh\n",
    "            self.dL_dWx = self.dL_dWx + (dL_dh_raw.T @ x_t)                    # Gradient w.r.t. Wx\n",
    "            self.dL_dWh = self.dL_dWh + dL_dh_raw.T @ h_prev                   # Gradient w.r.t. Wh\n",
    "            self.dL_dbh = self.dL_dbh + dL_dh_raw.T @ np.ones((batch_size, 1)) # Gradient w.r.t. bh\n",
    "            dL_dh = dL_dh_raw @ self.Wh                                        # Gradient w.r.t. previous hidden state (Wh)\n",
    "            ### END CODE HERE ###\n",
    "\n",
    "        ### START CODE HERE ###\n",
    "        # Average gradients over the batch.\n",
    "        self.dL_dWx = self.dL_dWx / batch_size\n",
    "        self.dL_dWh = self.dL_dWh / batch_size\n",
    "        self.dL_dbh = self.dL_dbh / batch_size\n",
    "        ### END CODE HERE ###\n",
    "\n",
    "        ### START CODE HERE ###\n",
    "        # Gradient part (optional), you can't run this part while testing the backward function !!!\n",
    "        # clip_value = 2.0\n",
    "        # Clip gradients to prevent exploding gradients\n",
    "        # np.clip(self.dL_dWx, -clip_value, clip_value, out=self.dL_dWx)\n",
    "        # np.clip(self.dL_dWh, -clip_value, clip_value, out=self.dL_dWh)\n",
    "        # np.clip(self.dL_dbh, -clip_value, clip_value, out=self.dL_dbh)\n",
    "        ### END CODE HERE ###\n",
    "\n",
    "        return dL_dh\n",
    "\n",
    "    def update(self, learning_rate):\n",
    "        \"\"\"\n",
    "        Update the weights and biases using the computed gradients.\n",
    "\n",
    "        Parameters:\n",
    "        learning_rate (float): Learning rate for weight updates.\n",
    "        \"\"\"\n",
    "        ### START CODE HERE ###\n",
    "        # Update each weights.\n",
    "        self.Wx = self.Wx - learning_rate * self.dL_dWx\n",
    "        self.Wh = self.Wh - learning_rate * self.dL_dWh\n",
    "        self.bh = self.bh - learning_rate * self.dL_dbh\n",
    "        ### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZkQSHtRPMb73"
   },
   "source": [
    "### Functions testing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KKZFZhPfP9z-"
   },
   "source": [
    "#### `initialize_parameter` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "id": "F6x4VR14P9X3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wx shape: (3, 5)\n",
      "Wh shape: (3, 3)\n",
      "bh shape: (3, 1)\n"
     ]
    }
   ],
   "source": [
    "def test_initialization(save_to_output = False):\n",
    "    input_size = 5\n",
    "    rnn_units = 3\n",
    "    rnn = RNN(input_size, rnn_units)\n",
    "    print(\"Wx shape:\", rnn.Wx.shape)\n",
    "    print(\"Wh shape:\", rnn.Wh.shape)\n",
    "    print(\"bh shape:\", rnn.bh.shape)\n",
    "    if save_to_output == True:\n",
    "        outputs['RNN_initialization'] = {\"Wx shape\": rnn.Wx.shape, \"Wh shape\": rnn.Wh.shape, \"bh shape\": rnn.bh.shape}\n",
    "test_initialization(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TPEe5c4NQigx"
   },
   "source": [
    "Expected output:\n",
    "\n",
    "|Output|Value|\n",
    "|---|---|\n",
    "|Wx shape:|(3, 5)|\n",
    "|Wh shape:|(3, 3)|\n",
    "|bh shape:|(3, 1)|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oz_VET-YNtla"
   },
   "source": [
    "#### `forward` function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "id": "-7svLiJmFdEB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (2, 4, 5)\n",
      "Input:\n",
      "[[[ 1.62434536 -0.61175641 -0.52817175 -1.07296862  0.86540763]\n",
      "  [-2.3015387   1.74481176 -0.7612069   0.3190391  -0.24937038]\n",
      "  [ 1.46210794 -2.06014071 -0.3224172  -0.38405435  1.13376944]\n",
      "  [-1.09989127 -0.17242821 -0.87785842  0.04221375  0.58281521]]\n",
      "\n",
      " [[-1.10061918  1.14472371  0.90159072  0.50249434  0.90085595]\n",
      "  [-0.68372786 -0.12289023 -0.93576943 -0.26788808  0.53035547]\n",
      "  [-0.69166075 -0.39675353 -0.6871727  -0.84520564 -0.67124613]\n",
      "  [-0.0126646  -1.11731035  0.2344157   1.65980218  0.74204416]]]\n",
      "Output shape of RNN layer: (2, 3)\n",
      "Output of the RNN layer (hidden state):\n",
      "[[-0.00873835  0.02641052 -0.00287992]\n",
      " [-0.00596289 -0.01742189  0.02418844]]\n"
     ]
    }
   ],
   "source": [
    "def test_forward(seed, save_to_output = False):\n",
    "    input_size = 5\n",
    "    rnn_units = 3\n",
    "    batch_size = 2\n",
    "    timesteps = 4\n",
    "    # Initialize the RNN layer\n",
    "    rnn = RNN(input_size, rnn_units)\n",
    "    # Create a sample input of shape (batch_size, timesteps, input_size)\n",
    "    np.random.seed(seed)   # Don't change the seed!\n",
    "    X = np.random.randn(batch_size, timesteps, input_size)\n",
    "    # Perform the forward pass\n",
    "    output = rnn.forward(X)\n",
    "\n",
    "    if save_to_output == False:\n",
    "        # Print the output\n",
    "        print(\"Input shape:\", X.shape)\n",
    "        print(\"Input:\")\n",
    "        print(X)\n",
    "        print(\"Output shape of RNN layer:\", output.shape)\n",
    "        print(\"Output of the RNN layer (hidden state):\")\n",
    "        print(output)\n",
    "\n",
    "    if save_to_output == True:\n",
    "        outputs['RNN_forward'] = {\"X shape\": X.shape, \"X\": X, \"Output shape\": output.shape, \"Output\": output}\n",
    "\n",
    "# Run the test with seed 1 to compare with expected outputs.\n",
    "test_forward(1)\n",
    "\n",
    "# Run with seed 42 and save the answer.\n",
    "test_forward(42, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GxLx95MZGEqX"
   },
   "source": [
    "Expected output of `forward`:\n",
    "\n",
    "| Output | Value |\n",
    "|---|---|\n",
    "| Input shape | (2, 4, 5) |\n",
    "| Input | `[[[ 1.62434536 -0.61175641 -0.52817175 -1.07296862  0.86540763]`<br>  `[-2.3015387   1.74481176 -0.7612069   0.3190391  -0.24937038]`<br>  `[ 1.46210794 -2.06014071 -0.3224172  -0.38405435  1.13376944]`<br>  `[-1.09989127 -0.17242821 -0.87785842  0.04221375  0.58281521]]`<br><br> `[[-1.10061918  1.14472371  0.90159072  0.50249434  0.90085595]`<br>  `[-0.68372786 -0.12289023 -0.93576943 -0.26788808  0.53035547]`<br>  `[-0.69166075 -0.39675353 -0.6871727  -0.84520564 -0.67124613]`<br>  `[-0.0126646  -1.11731035  0.2344157   1.65980218  0.74204416]]]]` |\n",
    "| Output shape of RNN layer | (2, 3) |\n",
    "| Output of the RNN layer (hidden state) | `[[-0.00873835  0.02641052 -0.00287992]`<br> `[-0.00596289 -0.01742189  0.02418844]]` |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OTRcUEWzN143"
   },
   "source": [
    "#### `backward` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "id": "hc5rkLYhJHYd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dH shape:  (2, 3)\n",
      "dH:\n",
      "[[-0.19183555 -0.88762896 -0.74715829]\n",
      " [ 1.6924546   0.05080775 -0.63699565]]\n",
      "dL_dX shape: (2, 3)\n",
      "Gradient w.r.t. input (dL_dX):\n",
      "[[-1.30293142e-08  5.55316892e-09 -2.93987480e-08]\n",
      " [ 8.78019041e-09  2.41595285e-08 -1.33357681e-08]]\n",
      "dL_dWx shape: (3, 5)\n",
      "Gradient w.r.t. Wx (dL_dWx):\n",
      "[[ 0.09855041 -0.91665683  0.29245483  1.41272981  0.57684949]\n",
      " [ 0.48200032  0.06164319  0.40009246  0.02920006 -0.24340623]\n",
      " [ 0.42661386  0.4160692   0.25830352 -0.53769917 -0.44331323]]\n",
      "dL_dWh shape: (3, 3)\n",
      "Gradient w.r.t. Wh (dL_dWh):\n",
      "[[-0.00663169  0.01738478 -0.0106337 ]\n",
      " [-0.02325593  0.03069429 -0.03469078]\n",
      " [-0.01936184  0.02200992 -0.02853306]]\n",
      "dL_dbh shape: (3, 1)\n",
      "Gradient w.r.t. bh (dL_dbh):\n",
      "[[ 0.73406116]\n",
      " [-0.42812618]\n",
      " [-0.69714697]]\n"
     ]
    }
   ],
   "source": [
    "def test_backward(seed, save_to_output = False):\n",
    "    input_size = 5\n",
    "    rnn_units = 3\n",
    "    batch_size = 2\n",
    "    timesteps = 4\n",
    "\n",
    "    # Initialize the RNN layer\n",
    "    rnn = RNN(input_size, rnn_units)\n",
    "    np.random.seed(seed)   # Don't change the seed!\n",
    "    # Create a sample input of shape (batch_size, timesteps, input_size)\n",
    "    X = np.random.randn(batch_size, timesteps, input_size)\n",
    "    # Perform the forward pass\n",
    "    rnn.forward(X)\n",
    "    # Create a sample gradient of the loss with respect to the hidden state\n",
    "    dH = np.random.randn(batch_size, rnn_units)\n",
    "    # Perform the backward pass\n",
    "    dL_dX = rnn.backward(dH)\n",
    "    if save_to_output == False:\n",
    "        print(\"dH shape: \", dH.shape)\n",
    "        print(\"dH:\")\n",
    "        print(dH)\n",
    "        # Print the gradients\n",
    "        print(\"dL_dX shape:\", dL_dX.shape)\n",
    "        print(\"Gradient w.r.t. input (dL_dX):\")\n",
    "        print(dL_dX)\n",
    "        print(\"dL_dWx shape:\", rnn.dL_dWx.shape)\n",
    "        print(\"Gradient w.r.t. Wx (dL_dWx):\")\n",
    "        print(rnn.dL_dWx)\n",
    "        print(\"dL_dWh shape:\", rnn.dL_dWh.shape)\n",
    "        print(\"Gradient w.r.t. Wh (dL_dWh):\")\n",
    "        print(rnn.dL_dWh)\n",
    "        print(\"dL_dbh shape:\", rnn.dL_dbh.shape)\n",
    "        print(\"Gradient w.r.t. bh (dL_dbh):\")\n",
    "        print(rnn.dL_dbh)\n",
    "\n",
    "    if save_to_output == True:\n",
    "        outputs['RNN_backward'] = {\"dH shape\": dH.shape, \"dH\": dH, \"dL_dX shape\": dL_dX.shape, \"dL_dX\": dL_dX, \"dL_dWx shape\": rnn.dL_dWx.shape,\n",
    "                                   \"dL_dWx\": rnn.dL_dWx, \"dL_dWh shape\": rnn.dL_dWh.shape, \"dL_dWh\": rnn.dL_dWh, \"dL_dbh shape\": rnn.dL_dbh.shape, \"dL_dbh\": rnn.dL_dbh}\n",
    "\n",
    "# Run the test with seed 1 to compare with expected outputs.\n",
    "test_backward(1)\n",
    "\n",
    "# Run with seed 42 and save the answer.\n",
    "test_backward(42, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l0rtq6lDJSx8"
   },
   "source": [
    "Expected output:\n",
    "\n",
    "| Output | Value |\n",
    "|---|---|\n",
    "|dH shape:|(2, 3)|\n",
    "|dH:|`[[-0.19183555 -0.88762896 -0.74715829]`<br>`[ 1.6924546   0.05080775 -0.63699565]]`|\n",
    "|dL_dX shape:| (2, 3)|\n",
    "|Gradient w.r.t. input (dL_dX):| `[[-1.30293142e-08  5.55316892e-09 -2.93987480e-08]`<br>`[ 8.78019041e-09  2.41595285e-08 -1.33357681e-08]]`|\n",
    "|dL_dWx shape:| (3, 5)|\n",
    "|Gradient w.r.t. Wx (dL_dWx):|`[[ 0.09855041 -0.91665683  0.29245483  1.41272981  0.57684949]`<br>`[ 0.48200032  0.06164319  0.40009246  0.02920006 -0.24340623]`<br>`[ 0.42661386  0.4160692   0.25830352 -0.53769917 -0.44331323]]`|\n",
    "|dL_dWh shape:| (3, 3)|\n",
    "|Gradient w.r.t. Wh (dL_dWh):|`[[-0.00663169  0.01738478 -0.0106337 ]`<br>`[-0.02325593  0.03069429 -0.03469078]`<br>`[-0.01936184  0.02200992 -0.02853306]]`|\n",
    "|dL_dbh shape:| (3, 1)|\n",
    "|Gradient w.r.t. bh (dL_dbh):|`[[ 0.73406116]`<br>`[-0.42812618]`<br>`[-0.69714697]]`|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3_--VLgVCdpi"
   },
   "source": [
    "## Model class (10%)\n",
    "The `Model` class provides a framework for building and training neural networks.\n",
    "1.   `add()` is just like the function in previous Lab, we can call `model.add( )` to sequentially add a layer into the model.\n",
    "2.   `forward()` performs the forward propagation of data through the layers, calculating predictions\n",
    "3.   In `backward()`, we have to check if the activation function is *softmax* to make sure we call the right `backward()`.\n",
    "4.   `train()` function will be used to train the model, here, we can decide which loss function `BCE` or `MSE` we want to train with. And also calculate the loss for validation data.\n",
    "5. `plot_losses()` function can show the history of the training and validation loss to see if the training works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "id": "LlyznHZjCc0K"
   },
   "outputs": [],
   "source": [
    "class Model():\n",
    "    def __init__(self):\n",
    "        self.layers = []\n",
    "\n",
    "    def add(self, layer):\n",
    "        \"\"\"\n",
    "        Sequentially add a layer into the model.\n",
    "\n",
    "        Parameters:\n",
    "        layer: Different layers class.\n",
    "        \"\"\"\n",
    "        ### START CODE HERE ###\n",
    "        self.layers.append(layer)\n",
    "        ### END CODE HERE ###\n",
    "\n",
    "    def forward(self, X):\n",
    "        for layer in self.layers:\n",
    "            if layer.__class__.__name__ == 'RNN':\n",
    "                if len(X.shape) < 3:                                # If the RNN layer is stacked after another RNN layer.\n",
    "                    ### START CODE HERE ###\n",
    "                    X = np.expand_dims(X, axis=1)                # We have to treat the output size of first layer (rnn_units) as the feature size (input_size) of the second layer.\n",
    "                    ### END CODE HERE ###\n",
    "                X = layer.forward(X)\n",
    "            else:\n",
    "                X = layer.forward(X)\n",
    "        return X\n",
    "\n",
    "    def backward(self, dA, Y):\n",
    "        for layer in reversed(self.layers):\n",
    "            if isinstance(layer, Activation) and layer.activation_function == \"softmax\":\n",
    "                ### START CODE HERE ###\n",
    "                dA = layer.backward(Y=Y)                   # softmax activation backward.\n",
    "                ### END CODE HERE ###\n",
    "            else:\n",
    "                ### START CODE HERE ###\n",
    "                dA = layer.backward(dA)\n",
    "                ### END CODE HERE ###\n",
    "        return dA\n",
    "\n",
    "    def update(self, learning_rate):\n",
    "        for layer in self.layers:       # Update for every layers.\n",
    "            ### START CODE HERE ###\n",
    "            if layer.__class__.__name__ in ['RNN', 'Dense']:\n",
    "                layer.update(learning_rate)\n",
    "            ### END CODE HERE ###\n",
    "\n",
    "    def train(self, X_train, y_train, X_val, y_val, epochs=10, learning_rate=0.001, batch_size = 32, loss_function='mse'):\n",
    "        self.train_losses = []  # Initialize a list to store training losses\n",
    "        self.val_losses = []  # Initialize a list to store validation losses\n",
    "        for epoch in range(epochs):\n",
    "            total_loss = 0\n",
    "            ### START CODE HERE ###\n",
    "            num_batches = X_train.shape[0] // batch_size    # Calculate the number of batches\n",
    "            ### END CODE HERE ###\n",
    "\n",
    "            with tqdm(total=num_batches, desc=f\"Epoch {epoch + 1}/{epochs}\", unit=\"batch\") as pbar:\n",
    "                for batch_idx in range(num_batches):\n",
    "\n",
    "                    ### START CODE HERE ###\n",
    "                    # Get the batch data\n",
    "                    X_batch = X_train[batch_idx * batch_size:(batch_idx + 1) * batch_size]\n",
    "                    y_batch = y_train[batch_idx * batch_size:(batch_idx + 1) * batch_size]\n",
    "                    ### END CODE HERE ###\n",
    "\n",
    "                    ### START CODE HERE ###\n",
    "                    # 1. Forward to get the prediction.\n",
    "                    # 2. Calculate the loss according to your parameters ('cce' or 'mse').\n",
    "                    # 3. Calculate dA.\n",
    "                    # 4. backward with the calculated dA.\n",
    "                    # 5. update the parameters.\n",
    "                    y_pred = self.forward(X_batch)\n",
    "                    # Compute loss\n",
    "                    if loss_function == 'cce':\n",
    "                        loss = compute_CCE_loss(y_pred, y_batch)\n",
    "                    elif loss_function == 'mse':\n",
    "                        loss = compute_MSE_loss(y_pred, y_batch)\n",
    "                    else:\n",
    "                        raise ValueError(\"Unsupported loss function\")\n",
    "\n",
    "                    total_loss += loss\n",
    "                    if self.layers[-1].activation_function == 'softmax':\n",
    "                        dA = -(y_batch / (y_pred + 1e-5) - (1 - y_batch) / (1 - y_pred + 1e-5))\n",
    "                    else:\n",
    "                        dA = y_pred - y_batch\n",
    "                    self.backward(dA, y_batch)\n",
    "                    self.update(learning_rate)\n",
    "                    ### END CODE HERE ###\n",
    "\n",
    "                    # Update the progress bar and loss every 5 iterations\n",
    "                    if (batch_idx + 1) % 5 == 0:\n",
    "                        pbar.set_postfix(loss=total_loss / (batch_idx + 1))\n",
    "                    pbar.update(1)  # Increment the progress bar by 1 unit\n",
    "\n",
    "                # Handle the remaining examples that do not fit into a full batch\n",
    "                if len(X_train) % batch_size != 0:\n",
    "\n",
    "                    # Get the remaining data\n",
    "                    ### START CODE HERE ###\n",
    "                    X_batch = X_train[batch_idx * batch_size:]\n",
    "                    y_batch = y_train[batch_idx * batch_size:]\n",
    "                    ### END CODE HERE ###\n",
    "\n",
    "                    ### START CODE HERE ###\n",
    "                    # Same as above in batch\n",
    "                    y_pred = self.forward(X_batch)\n",
    "                    # Compute loss\n",
    "                    if loss_function == 'cce':\n",
    "                        loss = compute_CCE_loss(y_pred, y_batch)\n",
    "                    elif loss_function == 'mse':\n",
    "                        loss = compute_MSE_loss(y_pred, y_batch)\n",
    "                    else:\n",
    "                        raise ValueError(\"Unsupported loss function\")\n",
    "\n",
    "                    total_loss += loss\n",
    "                    if self.layers[-1].activation_function == 'softmax':\n",
    "                        dA = -(y_batch / (y_pred + 1e-5) - (1 - y_batch) / (1 - y_pred + 1e-5))\n",
    "                    else:\n",
    "                        dA = y_pred - y_batch\n",
    "                    self.backward(dA, y_batch)\n",
    "                    self.update(learning_rate)\n",
    "                    ### END CODE HERE ###\n",
    "\n",
    "            ### START CODE HERE ###\n",
    "            avg_train_loss = total_loss / num_batches       # Calculate the average loss over batches.\n",
    "            ### END CODE HERE ###\n",
    "\n",
    "            self.train_losses.append(avg_train_loss)\n",
    "            print(f'Epoch {epoch + 1}/{epochs}, Training Loss: {avg_train_loss}')\n",
    "\n",
    "            # Validation part\n",
    "            ### START CODE HERE ###\n",
    "            # 1. Get the prediction\n",
    "            # 2. compute the loss ('mse', 'cce').\n",
    "            y_pred = self.forward(X_val)\n",
    "\n",
    "            if loss_function == 'cce':\n",
    "                val_loss = compute_CCE_loss(y_pred, y_val)\n",
    "            elif loss_function == 'mse':\n",
    "                val_loss = compute_MSE_loss(y_pred, y_val)\n",
    "            ### END CODE HERE ###\n",
    "\n",
    "            self.val_losses.append(val_loss)\n",
    "            print(f'Epoch {epoch + 1}/{epochs}, Validation Loss: {val_loss}')\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.forward(X)\n",
    "\n",
    "    def plot_losses(self):\n",
    "        plt.plot(self.train_losses, label='Training Loss')\n",
    "        plt.plot(self.val_losses, label='Validation Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "icEnOl_kR_r5"
   },
   "source": [
    "### `Model` class testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "id": "B2ON5fmPSCSj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AL:  [[0.50002597]\n",
      " [0.50011082]\n",
      " [0.49998505]]\n",
      "dA_prev:  [[ 1.62378331e-09  3.84694676e-09  6.02625343e-09 -1.21805669e-08]\n",
      " [ 1.62165475e-09  3.84752280e-09  6.02247634e-09 -1.21748332e-08]\n",
      " [ 1.62368851e-09  3.84622277e-09  6.02587086e-09 -1.21793784e-08]]\n",
      "Wx of RNN:  [[ 0.01609996]\n",
      " [-0.00598851]\n",
      " [-0.00519148]\n",
      " [-0.01059058]]\n",
      "Wh of RNN:  [[ 0.00865366 -0.02301519  0.01744827 -0.00761178]\n",
      " [ 0.00319076 -0.00249388  0.01462095 -0.02060167]\n",
      " [-0.00322391 -0.00384067  0.0113376  -0.0109991 ]\n",
      " [-0.00172383 -0.00877879  0.00042198  0.00582784]]\n",
      "bh of RNN:  [[ 0.00017288]\n",
      " [-0.00015564]\n",
      " [-0.00010827]\n",
      " [-0.00016452]]\n"
     ]
    }
   ],
   "source": [
    "def test_model_class(seed, save_to_output = False):\n",
    "    np.random.seed(seed)\n",
    "    input = np.random.randn(3, 3, 1)\n",
    "    Y = np.expand_dims(np.array([1,0,1]),-1)\n",
    "\n",
    "    model = Model()\n",
    "    model.add(RNN(1, 4))\n",
    "    model.add(RNN(4, 4))\n",
    "    model.add(Dense(4, 1))\n",
    "    model.add(Activation(\"sigmoid\", None))\n",
    "\n",
    "    AL = model.forward(input)\n",
    "    dA_prev = model.backward(AL, Y=Y)\n",
    "    model.update(0.1)\n",
    "    if save_to_output == False:\n",
    "        print(\"AL: \", AL)\n",
    "        print(\"dA_prev: \", dA_prev)\n",
    "        print(\"Wx of RNN: \", model.layers[0].Wx)\n",
    "        print(\"Wh of RNN: \", model.layers[0].Wh)\n",
    "        print(\"bh of RNN: \", model.layers[0].bh)\n",
    "\n",
    "    if save_to_output == True:\n",
    "        outputs['Model_class'] = {\"AL\": AL, \"dA_prev\": dA_prev, \"Wx of RNN\": model.layers[0].Wx, \"Wh of RNN\": model.layers[0].Wh, \"bh of RNN\": model.layers[0].bh}\n",
    "\n",
    "# Run the test with seed 1 to compare with expected outputs.\n",
    "test_model_class(1)\n",
    "\n",
    "# Run with seed 42 and save the answer.\n",
    "test_model_class(42, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Seg7OO12VOvh"
   },
   "source": [
    "Expected output:\n",
    "\n",
    "|Output|Value|\n",
    "|---|---|\n",
    "|AL:| `[[0.50002597]`<br>`[0.50011082]`<br>`[0.49998505]]`|\n",
    "|dA_prev:|`[[ 1.62378331e-09  3.84694676e-09  6.02625343e-09 -1.21805669e-08]`<br>`[ 1.62165475e-09  3.84752280e-09  6.02247634e-09 -1.21748332e-08]`<br>`[ 1.62368851e-09  3.84622277e-09  6.02587086e-09 -1.21793784e-08]]`|\n",
    "|Wx of RNN:| `[[ 0.01609996]`<br>`[-0.00598851]`<br>`[-0.00519148]`<br>`[-0.01059058]]`|\n",
    "|Wh of RNN:|`[[ 0.00865366 -0.02301519  0.01744827 -0.00761178]`<br>`[ 0.00319076 -0.00249388  0.01462095 -0.02060167]`<br>`[-0.00322391 -0.00384067  0.0113376  -0.0109991 ]`<br>`[-0.00172383 -0.00877879  0.00042198  0.00582784]]`|\n",
    "|bh of RNN:|  `[[ 0.00017288]`<br>`[-0.00015564]`<br>`[-0.00010827]`<br>`[-0.00016452]]`|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gEMEe8JMkmhE"
   },
   "source": [
    "### Save the above output to `.npy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "id": "W6SUWskHkmMd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN_initialization:\n",
      "  Wx shape: <class 'tuple'>\n",
      "  Wh shape: <class 'tuple'>\n",
      "  bh shape: <class 'tuple'>\n",
      "RNN_forward:\n",
      "  X shape: <class 'tuple'>\n",
      "  X: <class 'numpy.ndarray'>\n",
      "  Output shape: <class 'tuple'>\n",
      "  Output: <class 'numpy.ndarray'>\n",
      "RNN_backward:\n",
      "  dH shape: <class 'tuple'>\n",
      "  dH: <class 'numpy.ndarray'>\n",
      "  dL_dX shape: <class 'tuple'>\n",
      "  dL_dX: <class 'numpy.ndarray'>\n",
      "  dL_dWx shape: <class 'tuple'>\n",
      "  dL_dWx: <class 'numpy.ndarray'>\n",
      "  dL_dWh shape: <class 'tuple'>\n",
      "  dL_dWh: <class 'numpy.ndarray'>\n",
      "  dL_dbh shape: <class 'tuple'>\n",
      "  dL_dbh: <class 'numpy.ndarray'>\n",
      "Model_class:\n",
      "  AL: <class 'numpy.ndarray'>\n",
      "  dA_prev: <class 'numpy.ndarray'>\n",
      "  Wx of RNN: <class 'numpy.ndarray'>\n",
      "  Wh of RNN: <class 'numpy.ndarray'>\n",
      "  bh of RNN: <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "assert list(outputs.keys()) == ['RNN_initialization', 'RNN_forward', 'RNN_backward', 'Model_class']\n",
    "np.save('Lab6_outputs.npy', outputs)\n",
    "# sanity check for saved outputs\n",
    "submit = np.load(\"Lab6_outputs.npy\", allow_pickle=True).item()\n",
    "for key, value in submit.items():\n",
    "    if isinstance(value, dict):  # Check if value is a dictionary\n",
    "        print(f\"{key}:\")\n",
    "        for inner_key, inner_value in value.items():\n",
    "            print(f\"  {inner_key}: {type(inner_value)}\")  # Print type of inner values\n",
    "    else:\n",
    "        print(f\"{key}: {type(value)}\")  # Print type of other values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m-Q5MP76mda2"
   },
   "source": [
    "Expected output:\n",
    "\n",
    "\n",
    "```\n",
    "RNN_initialization:\n",
    "  Wx shape: <class 'tuple'>\n",
    "  Wh shape: <class 'tuple'>\n",
    "  bh shape: <class 'tuple'>\n",
    "RNN_forward:\n",
    "  X shape: <class 'tuple'>\n",
    "  X: <class 'numpy.ndarray'>\n",
    "  Output shape: <class 'tuple'>\n",
    "  Output: <class 'numpy.ndarray'>\n",
    "RNN_backward:\n",
    "  dH shape: <class 'tuple'>\n",
    "  dH: <class 'numpy.ndarray'>\n",
    "  dL_dX shape: <class 'tuple'>\n",
    "  dL_dX: <class 'numpy.ndarray'>\n",
    "  dL_dWx shape: <class 'tuple'>\n",
    "  dL_dWx: <class 'numpy.ndarray'>\n",
    "  dL_dWh shape: <class 'tuple'>\n",
    "  dL_dWh: <class 'numpy.ndarray'>\n",
    "  dL_dbh shape: <class 'tuple'>\n",
    "  dL_dbh: <class 'numpy.ndarray'>\n",
    "Model_class:\n",
    "  AL: <class 'numpy.ndarray'>\n",
    "  dA_prev: <class 'numpy.ndarray'>\n",
    "  Wx of RNN: <class 'numpy.ndarray'>\n",
    "  Wh of RNN: <class 'numpy.ndarray'>\n",
    "  bh of RNN: <class 'numpy.ndarray'>\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QOLxLMMl9BD9"
   },
   "source": [
    "## Sinusoidal wave dataset (20%)\n",
    "In this section, we will generate a dataset of sinusoidal waves with varying frequencies, amplitudes, and random phase shifts. The **last value** in each sequence will be used as the target prediction. This dataset will be used for training and validating a model.\n",
    "\n",
    "\n",
    "\n",
    "*   You can decide how many `num_samples`, `num_timesteps`, `freq_range` and `amp_range` you want to generate your own training dataset. (**there is no provided training dataset!**)\n",
    "* ⚠⚠ You need to download X_test.csv from Kaggle and put it into Sinewave directory. (Or you have to change the path when generating prediction)\n",
    "* For **testing data** on Kaggle, we used `num_timesteps = 100`, `0.5 <= freq_range <= 5` & `0.5 <= amp_range <= 5` to generate, your training dataset can try to cover these range in testing data.\n",
    "* You need submit the `y_test.csv` to Kaggle\n",
    "    * `MAPE <= 17%` -> 10 points\n",
    "    * `MAPE <= 14%` -> 20 points\n",
    "* **Kaggle Link**: https://www.kaggle.com/t/512f44fe285d4c1bb90c39884f8a2a33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "id": "4eIHk7hbB7Cg"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate Sinusoidal Wave Dataset\n",
    "\n",
    "def generate_sine_wave_data(num_samples, num_timesteps, freq_range, amp_range):\n",
    "    \"\"\"\n",
    "    Generate sine wave data with varying frequencies, amplitudes, and random phase shifts.\n",
    "    The last value in each sequence is used as the target prediction.\n",
    "\n",
    "    Parameters:\n",
    "    - num_samples: Number of samples to generate.\n",
    "    - num_timesteps: Number of timesteps for each sample.\n",
    "    - freq_range: Tuple of floor and ceiling of frequency range.\n",
    "    - amp_range: Tuple of floor and ceiling of amplitude range.\n",
    "\n",
    "    Returns:\n",
    "    - X: Generated sine wave data of shape (num_samples, num_timesteps - 1).\n",
    "    - y: Target values of shape (num_samples,).\n",
    "    \"\"\"\n",
    "    X = np.zeros((num_samples, num_timesteps - 1))\n",
    "    y = np.zeros(num_samples)\n",
    "    for i in range(num_samples):\n",
    "        ### START CODE HERE ###\n",
    "        # Choose the frequency, amplitude and shift phase value.\n",
    "        freq = np.random.uniform(freq_range[0], freq_range[1]) # Random choose from freq_range.\n",
    "        amp = np.random.uniform(amp_range[0], amp_range[1])    # Random choose from amp_range.\n",
    "        phase_shift = np.random.uniform(0, 2 * np.pi)          # Random choose from (0, 2*pi).\n",
    "        ### END CODE HERE ###\n",
    "\n",
    "        t = np.linspace(0, 2 * np.pi, num_timesteps)\n",
    "        sine_wave = amp * np.sin(freq * t + phase_shift)\n",
    "        X[i] = sine_wave[:-1]  # All but the last value\n",
    "        y[i] = sine_wave[-1]   # The last value\n",
    "    return X, y\n",
    "\n",
    "### START CODE HERE ###\n",
    "# You can modify to your preferred range and number of samples. (Note: It's recommended to cover the range of testing data mentioned above.)\n",
    "num_samples = 1600\n",
    "num_timesteps = 1000\n",
    "freq_range = (0.5, 5.0)  # Frequency range\n",
    "amp_range = (0.5, 5.0)   # Amplitude range\n",
    "### END CODE HERE ###\n",
    "\n",
    "X, y = generate_sine_wave_data(num_samples, num_timesteps, freq_range, amp_range)\n",
    "\n",
    "### START CODE HERE ###\n",
    "# Split data into training and validation sets\n",
    "X_train = X[:1200]\n",
    "y_train = y[:1200]\n",
    "X_val = X[1200:]\n",
    "y_val = y[1200:]\n",
    "### END CODE HERE ###\n",
    "\n",
    "# Plot an example sequence\n",
    "plt.plot(X_train[0], label='Input Sequence')\n",
    "plt.plot(np.arange(num_timesteps, num_timesteps + 1), y_train[0], 'ro', label='Target Value')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ambyK8w0CYko"
   },
   "source": [
    "### Construct the model with Dense layer only\n",
    "Here, we want you to construct the model with **Dense layer only** like you did in Lab4. You may modify the model structure and parameters in the way you like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "id": "NHebwBbOCeZy"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20: 100%|██████████| 9/9 [00:00<00:00, 360.01batch/s, loss=9.71]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Training Loss: 6.968788242473783\n",
      "Epoch 1/20, Validation Loss: 2.2103052198644266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/20: 100%|██████████| 9/9 [00:00<00:00, 529.64batch/s, loss=1.55]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20, Training Loss: 1.493761168941309\n",
      "Epoch 2/20, Validation Loss: 1.1459606092647356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/20: 100%|██████████| 9/9 [00:00<00:00, 500.06batch/s, loss=0.862]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20, Training Loss: 0.8578610958389725\n",
      "Epoch 3/20, Validation Loss: 0.7341505478739164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/20: 100%|██████████| 9/9 [00:00<00:00, 500.00batch/s, loss=0.597]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20, Training Loss: 0.5932152145822971\n",
      "Epoch 4/20, Validation Loss: 0.5244506755386877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/20: 100%|██████████| 9/9 [00:00<00:00, 360.02batch/s, loss=0.45]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20, Training Loss: 0.4473129857252986\n",
      "Epoch 5/20, Validation Loss: 0.3996083905263902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/20: 100%|██████████| 9/9 [00:00<00:00, 428.56batch/s, loss=0.355]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20, Training Loss: 0.3537154610322168\n",
      "Epoch 6/20, Validation Loss: 0.31788045154597705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/20: 100%|██████████| 9/9 [00:00<00:00, 473.80batch/s, loss=0.287]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20, Training Loss: 0.2886811004558833\n",
      "Epoch 7/20, Validation Loss: 0.26158941889365267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/20: 100%|██████████| 9/9 [00:00<00:00, 473.72batch/s, loss=0.238]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20, Training Loss: 0.24161883371728507\n",
      "Epoch 8/20, Validation Loss: 0.2219252777023521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/20: 100%|██████████| 9/9 [00:00<00:00, 449.96batch/s, loss=0.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20, Training Loss: 0.20666012428166772\n",
      "Epoch 9/20, Validation Loss: 0.19352531423101454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/20: 100%|██████████| 9/9 [00:00<00:00, 449.95batch/s, loss=0.172]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20, Training Loss: 0.1804564215464726\n",
      "Epoch 10/20, Validation Loss: 0.1727999402814094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/20: 100%|██████████| 9/9 [00:00<00:00, 529.45batch/s, loss=0.151]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20, Training Loss: 0.16024025884194015\n",
      "Epoch 11/20, Validation Loss: 0.15735290550689188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/20: 100%|██████████| 9/9 [00:00<00:00, 409.01batch/s, loss=0.134]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20, Training Loss: 0.14442724032286325\n",
      "Epoch 12/20, Validation Loss: 0.14560036182637404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/20: 100%|██████████| 9/9 [00:00<00:00, 321.40batch/s, loss=0.12]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20, Training Loss: 0.13173085879433077\n",
      "Epoch 13/20, Validation Loss: 0.13661699975944352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/20: 100%|██████████| 9/9 [00:00<00:00, 409.19batch/s, loss=0.109]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20, Training Loss: 0.1213501274137661\n",
      "Epoch 14/20, Validation Loss: 0.1296343140709026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/20: 100%|██████████| 9/9 [00:00<00:00, 321.53batch/s, loss=0.0996]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20, Training Loss: 0.11277023207282233\n",
      "Epoch 15/20, Validation Loss: 0.12409393790413481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/20: 100%|██████████| 9/9 [00:00<00:00, 473.74batch/s, loss=0.092]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20, Training Loss: 0.10551406588696348\n",
      "Epoch 16/20, Validation Loss: 0.11941457376303102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/20: 100%|██████████| 9/9 [00:00<00:00, 450.35batch/s, loss=0.0855]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20, Training Loss: 0.09931936429942229\n",
      "Epoch 17/20, Validation Loss: 0.11552437730026624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/20: 100%|██████████| 9/9 [00:00<00:00, 473.72batch/s, loss=0.08]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20, Training Loss: 0.09395403408536866\n",
      "Epoch 18/20, Validation Loss: 0.11218011009305326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/20: 100%|██████████| 9/9 [00:00<00:00, 449.96batch/s, loss=0.0752]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20, Training Loss: 0.08924037486304613\n",
      "Epoch 19/20, Validation Loss: 0.10916429944533407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/20: 100%|██████████| 9/9 [00:00<00:00, 428.54batch/s, loss=0.071]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20, Training Loss: 0.08502441573740996\n",
      "Epoch 20/20, Validation Loss: 0.10642007279819239\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### START CODE HERE ###\n",
    "# Change the structure and parameters to train your own model (Only contain Dense layer here!!!)\n",
    "# Reshape the input data to fit Dense model\n",
    "input_size = X_train.shape[1]\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1])\n",
    "X_val = X_val.reshape(X_val.shape[0], X_val.shape[1])\n",
    "y_val = y_val.reshape(-1, 1)\n",
    "y_train = y_train.reshape(-1, 1)\n",
    "# Construct the model with Dense layers\n",
    "\n",
    "model = Model()\n",
    "model.add(Dense(input_size, 64))\n",
    "model.add(Activation(\"relu\", None))\n",
    "model.add(Dense(64, 1))\n",
    "model.add(Activation(\"linear\", None))\n",
    "\n",
    "# Train the model\n",
    "model.train(X_train, y_train, X_val, y_val, epochs=20, learning_rate=0.001, batch_size = 128, loss_function='mse')\n",
    "### END CODE HERE ###\n",
    "\n",
    "# Plot the training and validation losses\n",
    "model.plot_losses()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xP0-p2yrD8gA"
   },
   "source": [
    "#### Predict testing data & Save the answer (For Dense model)\n",
    "For this prediction of Dense model, you can choose not to submit it to Kaggle if its performance is not better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "id": "_GNngIotD6Ow"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 999 is different from 99)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[160], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Convert the DataFrame to a numpy array\u001b[39;00m\n\u001b[0;32m     14\u001b[0m X_test \u001b[38;5;241m=\u001b[39m X_test_df\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m---> 15\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Convert the list of predictions to a numpy array\u001b[39;00m\n\u001b[0;32m     19\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(y_pred)\n",
      "Cell \u001b[1;32mIn[155], line 146\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m--> 146\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[155], line 25\u001b[0m, in \u001b[0;36mModel.forward\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     23\u001b[0m         X \u001b[38;5;241m=\u001b[39m layer\u001b[38;5;241m.\u001b[39mforward(X)\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 25\u001b[0m         X \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X\n",
      "File \u001b[1;32mc:\\Introduction_to_Machine_Learning\\Lab6\\Dense.py:43\u001b[0m, in \u001b[0;36mDense.forward\u001b[1;34m(self, A)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;124;03mImplement the linear part of a layer's forward propagation.\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;124;03mZ -- the input of the activation function, also called pre-activation parameter with the shape (n, f^[l])\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# GRADED FUNCTION: linear_forward\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m### START CODE HERE ###\u001b[39;00m\n\u001b[1;32m---> 43\u001b[0m Z \u001b[38;5;241m=\u001b[39m \u001b[43mA\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mW\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparameters[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache \u001b[38;5;241m=\u001b[39m (A, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparameters[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mW\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparameters[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m### END CODE HERE ###\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 999 is different from 99)"
     ]
    }
   ],
   "source": [
    "### START CODE HERE ###\n",
    "# Read the X_test.csv file into a DataFrame\n",
    "# Change the path if needed\n",
    "# download\n",
    "X_test_df = pd.read_csv('Sinewave/X_test.csv')\n",
    "### END CODE HERE ###\n",
    "\n",
    "# Do not modify this part to get the correct output format!!\n",
    "# Drop the 'Id' column if it exists\n",
    "if 'Id' in X_test_df.columns:\n",
    "    X_test_df = X_test_df.drop(columns=['Id'])\n",
    "\n",
    "# Convert the DataFrame to a numpy array\n",
    "X_test = X_test_df.values\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "# Convert the list of predictions to a numpy array\n",
    "y_pred = np.array(y_pred)\n",
    "y_pred_df = pd.DataFrame(y_pred, columns=['answer'])\n",
    "y_pred_df.insert(0, 'Id', range(1, 1 + len(y_pred_df)))\n",
    "y_pred_df.to_csv('y_pred_basic.csv', index=False)\n",
    "\n",
    "print('Prediction data has been saved.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0E7dvPVBBhgk"
   },
   "source": [
    "### Construct the model with RNN layer\n",
    "Then, we can integrate our custom-built RNN layer into the model to evaluate whether it improves performance on the sequential inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yIJd6igNCG8i"
   },
   "outputs": [],
   "source": [
    "### START CODE HERE ###\n",
    "# Change the structure and parameters to train your own model (Can add RNN layer here)\n",
    "# Reshape X_train and X_val to fit the RNN layer input shape.\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "X_val = X_val.reshape(X_val.shape[0], X_val.shape[1], 1)\n",
    "y_val = y_val.reshape(-1, 1)\n",
    "y_train = y_train.reshape(-1, 1)\n",
    "\n",
    "# Construct the model & Set the parameters.\n",
    "input_size = 1  # Number of input features (1 for single sine wave value)\n",
    "rnn_units = 32  # Number of units in the RNN layer\n",
    "dense_units = 16  # Number of units in the Dense layer\n",
    "output_size = 1  # Number of output classes (1 for single sine wave value)\n",
    "\n",
    "# model = Model()\n",
    "model.add(None)\n",
    "...\n",
    "\n",
    "# Train the model\n",
    "model.train(X_train, y_train, X_val, y_val, epochs=20, learning_rate=0.001, batch_size = 16, loss_function='mse')\n",
    "### END CODE HERE ###\n",
    "\n",
    "# Plot the training and validation losses\n",
    "model.plot_losses()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DafczhXYA0fJ"
   },
   "source": [
    "#### Predict testing data & Save the answer (For RNN model)\n",
    "Remember to submit your prediction to Kaggle!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kVkkIBwd-CWf"
   },
   "outputs": [],
   "source": [
    "### START CODE HERE ###\n",
    "# Read the X_test.csv file into a DataFrame\n",
    "# Change the path if needed\n",
    "X_test_df = pd.read_csv('Sinewave/X_test.csv')\n",
    "### END CODE HERE ###\n",
    "\n",
    "\n",
    "# Do not modify this part to get the correct output format!!\n",
    "# Drop the 'Id' column if it exists\n",
    "if 'Id' in X_test_df.columns:\n",
    "    X_test_df = X_test_df.drop(columns=['Id'])\n",
    "\n",
    "# Convert the DataFrame to a numpy array\n",
    "X_test = X_test_df.values\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))  # reshape the X_test to fit RNN layer input shape.\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "# Convert the list of predictions to a numpy array\n",
    "y_pred = np.array(y_pred)\n",
    "y_pred_df = pd.DataFrame(y_pred, columns=['answer'])\n",
    "y_pred_df.insert(0, 'Id', range(1, 1 + len(y_pred_df)))\n",
    "y_pred_df.to_csv('y_pred_basic.csv', index=False)\n",
    "\n",
    "print('Prediction data has been saved.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NNRANy31n8aW"
   },
   "source": [
    "# Advance part (35%)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nz7MTnsUFcyP"
   },
   "source": [
    "## Accelerometer and Gyroscope dataset\n",
    "- ⚠⚠ You need to download the training & testing data from Kaggle. ⚠⚠ (Put it into the directory name `Activity data`, or your need to change the path in template.)\n",
    "- In this dataset, we provide the time-series Accelerometer and Gyroscope data each with 3-axial (x, y, z) (total 6 channels).\n",
    "- We classified the activity into 3 different classes:\n",
    "    Activity 1, 2, 3\\\n",
    "    You have to build a RNN model using these time-series data to predict the activity class.\n",
    "- Steps:\n",
    "    1. Load the provided `X_train.npy`, `y_train.npy` and `X_test.npy` and split the part of training data to validation.\\\n",
    "    Note: `y_train.npy` is already one-hot encoded.\n",
    "    2. Visualize the `X_train.npy`.\n",
    "    3. One-hot encode the `y_train.npy` for three classes: Activity 1, Activity 2, Activity 3.\n",
    "    4. Build your own RNN model and train it.\n",
    "    5. Predict with the `X_test.npy` and generate `y_test.csv` then **submit it to Kaggle**!\n",
    "- We have set 3 baselines on public score:\n",
    "    * Accuracy >= 0.65 -> 10 points\n",
    "    * Accuracy >= 0.7  -> 20 points\n",
    "    * Accuracy >= 0.75 -> 25 points\n",
    "- Kaggle link: https://www.kaggle.com/t/95e0b11f63e74566802b0dea5ec4f1b4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AYo4WYfMHws_"
   },
   "source": [
    "### 1. Load training & testing data\n",
    "Load the training and testing data, then split the training data into a validation set using your preferred ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kmP1Uo4PlIwV"
   },
   "outputs": [],
   "source": [
    "### START CODE HERE ###\n",
    "# Load X_train, y_train and X_test data\n",
    "# Change the path if needed\n",
    "y_train = np.load('Activity data/y_train.npy')\n",
    "X_train = np.load('Activity data/X_train.npy')\n",
    "X_test = np.load('Activity data/X_test.npy')\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "### END CODE HERE ###\n",
    "\n",
    "### START CODE HERE ###\n",
    "# Define the validation ratio in your preferred way\n",
    "# 1. One-hot encode y_train. (3 classes)\n",
    "# 2. Split the X_train, y_train data into train & validation set.\n",
    "validation_ratio = 0.15\n",
    "None\n",
    "### END CODE HERE ###\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h0u30s9HLcIL"
   },
   "source": [
    "### 2. Visualize the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XeD88dTg6oSI"
   },
   "outputs": [],
   "source": [
    "# Function to plot a single sample\n",
    "def plot_sample(X, y, sample_index):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(X[sample_index, :, 0], label='Acc X')\n",
    "    plt.plot(X[sample_index, :, 1], label='Acc Y')\n",
    "    plt.plot(X[sample_index, :, 2], label='Acc Z')\n",
    "    plt.plot(X[sample_index, :, 3], label='Gyro X')\n",
    "    plt.plot(X[sample_index, :, 4], label='Gyro Y')\n",
    "    plt.plot(X[sample_index, :, 5], label='Gyro Z')\n",
    "    plt.title(f'Sample {sample_index} - Activity: {np.argmax(y[sample_index])}')\n",
    "    plt.xlabel('Time Step')\n",
    "    plt.ylabel('Sensor Value')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "### START CODE HERE ###\n",
    "# Plot a few samples\n",
    "for i in range(3):              # Change the range to visualize more samples\n",
    "    plot_sample(X_train, y_train, i)\n",
    " ### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "doO7vRXk2t1w"
   },
   "source": [
    "### 3. Contruct and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0nRlh-1qSsi2"
   },
   "outputs": [],
   "source": [
    "### START CODE HERE ###\n",
    "# Construct the model & Set the parameters.\n",
    "input_size = 6  # Number of input features (1 for single sine wave value)\n",
    "rnn_units = 64  # Number of units in the RNN layer\n",
    "dense_units = 32  # Number of units in the Dense layer\n",
    "output_size = 3  # Number of output classes\n",
    "\n",
    "model = Model()\n",
    "model.add(None)\n",
    "...\n",
    "# Train the model\n",
    "model.train(X_train, y_train, X_val, y_val, epochs=50, learning_rate=0.008, batch_size = 32, loss_function='cce')\n",
    "\n",
    "### END CODE HERE ###\n",
    "# Plot the training and validation losses\n",
    "model.plot_losses()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_43jkUMbJKsR"
   },
   "source": [
    "### 4. Predict the output and Save it\n",
    "Remember to submit `y_pred.csv` to Kaggle!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "detzXpDb8mQn"
   },
   "outputs": [],
   "source": [
    "# Do not modify this part to get the correct output format!!\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "# Save the predicted classes to a CSV file\n",
    "y_pred_df = pd.DataFrame({\n",
    "    'Id': np.arange(len(y_pred_classes)),\n",
    "    'Classes': y_pred_classes\n",
    "})\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "y_pred_df.to_csv('y_pred_advanced.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
