助教好，

我是 Team 13 的組員劉祐廷，我們目前有成功訓練出稍微能用的模型 (by DAE)，目前在思考要如何改進它的效能。不過由於網路上的資料大部分是將 DAE 用於影像上的，用於音訊上的資料比較少，因此我們有些問題想詢問助教：

1. Layer 的 function 和 node 數量應該要怎麼設計，有沒有什麼原則可以依循？
2. 網路上的資料 Loss function 大部分只查的到 MSE, ME 和RMSE，請問還有其他可能適合的 function 嗎？
3. 目前有畫出音檔的 waveform 和 Mel 頻譜圖，我們不太知道要怎麼將成果、數據、或是訓練過程視覺化，助教可以給我們一點建議嗎？

模型設計：
self.encoder = nn.Sequential(
    nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1), 
    nn.ReLU(),
    nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=1),
    nn.ReLU(),
    nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1),
    nn.ReLU(),
)
# 解碼器
self.decoder = nn.Sequential(
    nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2, padding=1, output_padding=1),
    nn.ReLU(),
    nn.ConvTranspose2d(32, 16, kernel_size=3, stride=2, padding=1, output_padding=1),
    nn.ReLU(),
    nn.ConvTranspose2d(16, 1, kernel_size=3, stride=2, padding=1, output_padding=1),
)